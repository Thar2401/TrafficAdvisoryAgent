# Test integration and performance\n\nimport unittest\nimport pandas as pd\nimport numpy as np\nimport time\nimport sys\nimport os\nfrom unittest.mock import Mock, patch\n\n# Add parent directory to path\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom src.traffic_agent import TrafficAdvisoryAgent\nfrom utils.data_generator import TrafficDataGenerator\nfrom utils.config import Config\n\nclass TestSystemIntegration(unittest.TestCase):\n    \"\"\"Test complete system integration\"\"\"\n    \n    @classmethod\n    def setUpClass(cls):\n        \"\"\"Set up test fixtures for integration tests\"\"\"\n        # Generate comprehensive test data\n        generator = TrafficDataGenerator()\n        routes = generator.generate_routes(50)\n        cls.test_data = generator.generate_traffic_patterns(routes, days=14)\n        \n        # Initialize traffic agent\n        cls.agent = TrafficAdvisoryAgent()\n        cls.agent.initialize(cls.test_data)\n    \n    def test_end_to_end_workflow(self):\n        \"\"\"Test complete end-to-end workflow\"\"\"\n        # Test request\n        user_request = {\n            'source': 'Downtown',\n            'destination': 'Airport',\n            'preferred_time': '08:00',\n            'day_of_week': 1,\n            'preferences': ['time_efficient', 'eco_friendly']\n        }\n        \n        # Process request\n        start_time = time.time()\n        response = self.agent.process_request(user_request)\n        processing_time = time.time() - start_time\n        \n        # Validate response structure\n        self.assertIn('recommendations', response)\n        self.assertIn('processing_time', response)\n        self.assertIn('confidence', response)\n        self.assertIn('timestamp', response)\n        \n        # Validate recommendations content\n        recommendations = response['recommendations']\n        self.assertIn('primary_recommendation', recommendations)\n        self.assertIn('alternatives', recommendations)\n        self.assertIn('insights', recommendations)\n        \n        # Validate primary recommendation\n        primary = recommendations['primary_recommendation']\n        self.assertIn('route', primary)\n        self.assertIn('timing', primary)\n        self.assertIn('justification', primary)\n        \n        # Performance check\n        self.assertLess(processing_time, 5.0)  # Should complete within 5 seconds\n    \n    def test_multiple_route_scenarios(self):\n        \"\"\"Test various route scenarios\"\"\"\n        scenarios = [\n            {\n                'name': 'rush_hour_commute',\n                'request': {\n                    'source': 'Suburb',\n                    'destination': 'Business District',\n                    'preferred_time': '08:30',\n                    'day_of_week': 1,\n                    'preferences': ['time_efficient']\n                }\n            },\n            {\n                'name': 'off_peak_leisure',\n                'request': {\n                    'source': 'Downtown',\n                    'destination': 'Park',\n                    'preferred_time': '14:00',\n                    'day_of_week': 6,\n                    'preferences': ['eco_friendly']\n                }\n            },\n            {\n                'name': 'evening_return',\n                'request': {\n                    'source': 'Mall',\n                    'destination': 'Residential',\n                    'preferred_time': '18:00',\n                    'day_of_week': 2,\n                    'preferences': ['cost_effective']\n                }\n            }\n        ]\n        \n        for scenario in scenarios:\n            with self.subTest(scenario=scenario['name']):\n                response = self.agent.process_request(scenario['request'])\n                \n                # Each scenario should get valid recommendations\n                self.assertIn('recommendations', response)\n                self.assertGreater(response['confidence'], 0.0)\n                \n                # Should have appropriate insights for the scenario\n                insights = response['recommendations']['insights']\n                self.assertIsInstance(insights, list)\n                self.assertGreater(len(insights), 0)\n    \n    def test_preference_handling(self):\n        \"\"\"Test different preference combinations\"\"\"\n        base_request = {\n            'source': 'Downtown',\n            'destination': 'Airport',\n            'preferred_time': '08:00',\n            'day_of_week': 1\n        }\n        \n        preference_tests = [\n            ['time_efficient'],\n            ['eco_friendly'],\n            ['cost_effective'],\n            ['time_efficient', 'eco_friendly'],\n            ['eco_friendly', 'cost_effective'],\n            ['time_efficient', 'cost_effective']\n        ]\n        \n        for preferences in preference_tests:\n            with self.subTest(preferences=preferences):\n                request = base_request.copy()\n                request['preferences'] = preferences\n                \n                response = self.agent.process_request(request)\n                \n                # Should adapt recommendations based on preferences\n                self.assertIn('recommendations', response)\n                \n                # Justification should mention the preferences\n                justification = response['recommendations']['primary_recommendation']['justification']\n                self.assertIsInstance(justification, str)\n                self.assertGreater(len(justification), 20)\n    \n    def test_data_consistency(self):\n        \"\"\"Test data consistency across multiple requests\"\"\"\n        # Same request should give consistent results\n        request = {\n            'source': 'Downtown',\n            'destination': 'Airport',\n            'preferred_time': '08:00',\n            'day_of_week': 1,\n            'preferences': ['time_efficient']\n        }\n        \n        responses = []\n        for _ in range(3):\n            response = self.agent.process_request(request)\n            responses.append(response)\n        \n        # Core recommendations should be consistent\n        primary_routes = [r['recommendations']['primary_recommendation']['route'] for r in responses]\n        \n        # Should have same source and destination\n        for route in primary_routes:\n            self.assertEqual(route['source'], 'Downtown')\n            self.assertEqual(route['destination'], 'Airport')\n    \n    def test_error_handling(self):\n        \"\"\"Test system error handling\"\"\"\n        # Test invalid source\n        invalid_request = {\n            'source': 'NonexistentLocation',\n            'destination': 'Airport',\n            'preferred_time': '08:00',\n            'day_of_week': 1,\n            'preferences': ['time_efficient']\n        }\n        \n        response = self.agent.process_request(invalid_request)\n        \n        # Should handle gracefully\n        self.assertIn('error', response or {})\n        \n        # Test invalid time format\n        invalid_time_request = {\n            'source': 'Downtown',\n            'destination': 'Airport',\n            'preferred_time': '25:00',  # Invalid hour\n            'day_of_week': 1,\n            'preferences': ['time_efficient']\n        }\n        \n        response = self.agent.process_request(invalid_time_request)\n        # Should either handle gracefully or provide error information\n        self.assertTrue('error' in response or 'recommendations' in response)\n\nclass TestPerformanceBenchmarks(unittest.TestCase):\n    \"\"\"Test system performance benchmarks\"\"\"\n    \n    @classmethod\n    def setUpClass(cls):\n        \"\"\"Set up performance test fixtures\"\"\"\n        # Generate larger dataset for performance testing\n        generator = TrafficDataGenerator()\n        routes = generator.generate_routes(100)\n        cls.test_data = generator.generate_traffic_patterns(routes, days=30)\n        \n        cls.agent = TrafficAdvisoryAgent()\n        cls.agent.initialize(cls.test_data)\n    \n    def test_single_request_performance(self):\n        \"\"\"Test single request processing performance\"\"\"\n        request = {\n            'source': 'Downtown',\n            'destination': 'Airport',\n            'preferred_time': '08:00',\n            'day_of_week': 1,\n            'preferences': ['time_efficient']\n        }\n        \n        # Warm up\n        self.agent.process_request(request)\n        \n        # Benchmark\n        start_time = time.time()\n        response = self.agent.process_request(request)\n        processing_time = time.time() - start_time\n        \n        # Performance requirements\n        self.assertLess(processing_time, 2.0)  # Should complete within 2 seconds\n        self.assertIn('recommendations', response)\n        \n        print(f\"Single request processing time: {processing_time:.3f}s\")\n    \n    def test_batch_processing_performance(self):\n        \"\"\"Test batch processing performance\"\"\"\n        # Generate batch of requests\n        batch_requests = []\n        for i in range(10):\n            request = {\n                'source': 'Downtown',\n                'destination': f'Destination_{i%5}',\n                'preferred_time': f'{8+i%8:02d}:00',\n                'day_of_week': (i % 7) + 1,\n                'preferences': ['time_efficient']\n            }\n            batch_requests.append(request)\n        \n        # Benchmark batch processing\n        start_time = time.time()\n        responses = self.agent.process_batch_requests(batch_requests)\n        batch_processing_time = time.time() - start_time\n        \n        # Validate results\n        self.assertEqual(len(responses), len(batch_requests))\n        \n        # Performance requirements\n        avg_time_per_request = batch_processing_time / len(batch_requests)\n        self.assertLess(avg_time_per_request, 1.0)  # Should average < 1s per request\n        \n        print(f\"Batch processing time: {batch_processing_time:.3f}s for {len(batch_requests)} requests\")\n        print(f\"Average time per request: {avg_time_per_request:.3f}s\")\n    \n    def test_memory_usage(self):\n        \"\"\"Test memory usage during processing\"\"\"\n        import psutil\n        import os\n        \n        process = psutil.Process(os.getpid())\n        initial_memory = process.memory_info().rss / 1024 / 1024  # MB\n        \n        # Process multiple requests\n        for i in range(50):\n            request = {\n                'source': 'Downtown',\n                'destination': f'Destination_{i%10}',\n                'preferred_time': f'{8+i%12:02d}:00',\n                'day_of_week': (i % 7) + 1,\n                'preferences': ['time_efficient']\n            }\n            self.agent.process_request(request)\n        \n        final_memory = process.memory_info().rss / 1024 / 1024  # MB\n        memory_increase = final_memory - initial_memory\n        \n        # Memory increase should be reasonable\n        self.assertLess(memory_increase, 100)  # Less than 100MB increase\n        \n        print(f\"Memory usage: {initial_memory:.1f}MB -> {final_memory:.1f}MB (+{memory_increase:.1f}MB)\")\n    \n    def test_concurrent_processing(self):\n        \"\"\"Test concurrent request processing\"\"\"\n        import threading\n        import queue\n        \n        results = queue.Queue()\n        errors = queue.Queue()\n        \n        def process_request(request_id):\n            try:\n                request = {\n                    'source': 'Downtown',\n                    'destination': f'Destination_{request_id%5}',\n                    'preferred_time': f'{8+request_id%8:02d}:00',\n                    'day_of_week': (request_id % 7) + 1,\n                    'preferences': ['time_efficient']\n                }\n                \n                start_time = time.time()\n                response = self.agent.process_request(request)\n                processing_time = time.time() - start_time\n                \n                results.put({'request_id': request_id, 'time': processing_time, 'success': True})\n            except Exception as e:\n                errors.put({'request_id': request_id, 'error': str(e)})\n        \n        # Create and start threads\n        threads = []\n        num_threads = 5\n        \n        start_time = time.time()\n        for i in range(num_threads):\n            thread = threading.Thread(target=process_request, args=(i,))\n            threads.append(thread)\n            thread.start()\n        \n        # Wait for completion\n        for thread in threads:\n            thread.join()\n        \n        total_time = time.time() - start_time\n        \n        # Collect results\n        result_list = []\n        while not results.empty():\n            result_list.append(results.get())\n        \n        error_list = []\n        while not errors.empty():\n            error_list.append(errors.get())\n        \n        # Validate concurrent processing\n        self.assertEqual(len(result_list), num_threads)\n        self.assertEqual(len(error_list), 0)  # No errors expected\n        \n        avg_processing_time = sum(r['time'] for r in result_list) / len(result_list)\n        \n        print(f\"Concurrent processing: {num_threads} requests in {total_time:.3f}s\")\n        print(f\"Average processing time: {avg_processing_time:.3f}s\")\n        \n        # Should handle concurrent requests efficiently\n        self.assertLess(avg_processing_time, 3.0)\n\nclass TestDataScalability(unittest.TestCase):\n    \"\"\"Test system scalability with different data sizes\"\"\"\n    \n    def test_small_dataset_performance(self):\n        \"\"\"Test performance with small dataset\"\"\"\n        # Small dataset: 20 routes, 7 days\n        generator = TrafficDataGenerator()\n        routes = generator.generate_routes(20)\n        small_data = generator.generate_traffic_patterns(routes, days=7)\n        \n        agent = TrafficAdvisoryAgent()\n        \n        # Measure initialization time\n        start_time = time.time()\n        agent.initialize(small_data)\n        init_time = time.time() - start_time\n        \n        # Test processing\n        request = {\n            'source': 'Downtown',\n            'destination': 'Airport',\n            'preferred_time': '08:00',\n            'day_of_week': 1,\n            'preferences': ['time_efficient']\n        }\n        \n        start_time = time.time()\n        response = agent.process_request(request)\n        processing_time = time.time() - start_time\n        \n        print(f\"Small dataset - Init: {init_time:.3f}s, Processing: {processing_time:.3f}s\")\n        \n        # Should be very fast with small data\n        self.assertLess(init_time, 5.0)\n        self.assertLess(processing_time, 1.0)\n        self.assertIn('recommendations', response)\n    \n    def test_large_dataset_performance(self):\n        \"\"\"Test performance with large dataset\"\"\"\n        # Large dataset: 200 routes, 60 days\n        generator = TrafficDataGenerator()\n        routes = generator.generate_routes(200)\n        large_data = generator.generate_traffic_patterns(routes, days=60)\n        \n        agent = TrafficAdvisoryAgent()\n        \n        # Measure initialization time\n        start_time = time.time()\n        agent.initialize(large_data)\n        init_time = time.time() - start_time\n        \n        # Test processing\n        request = {\n            'source': 'Downtown',\n            'destination': 'Airport',\n            'preferred_time': '08:00',\n            'day_of_week': 1,\n            'preferences': ['time_efficient']\n        }\n        \n        start_time = time.time()\n        response = agent.process_request(request)\n        processing_time = time.time() - start_time\n        \n        print(f\"Large dataset - Init: {init_time:.3f}s, Processing: {processing_time:.3f}s\")\n        print(f\"Dataset size: {len(large_data)} records\")\n        \n        # Should still be reasonable with large data\n        self.assertLess(init_time, 30.0)  # Initialization can be slower\n        self.assertLess(processing_time, 5.0)  # Processing should stay fast\n        self.assertIn('recommendations', response)\n\nclass TestSystemReliability(unittest.TestCase):\n    \"\"\"Test system reliability and robustness\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures\"\"\"\n        generator = TrafficDataGenerator()\n        routes = generator.generate_routes(30)\n        self.test_data = generator.generate_traffic_patterns(routes, days=10)\n        \n        self.agent = TrafficAdvisoryAgent()\n        self.agent.initialize(self.test_data)\n    \n    def test_repeated_processing_reliability(self):\n        \"\"\"Test system reliability under repeated processing\"\"\"\n        request = {\n            'source': 'Downtown',\n            'destination': 'Airport',\n            'preferred_time': '08:00',\n            'day_of_week': 1,\n            'preferences': ['time_efficient']\n        }\n        \n        success_count = 0\n        error_count = 0\n        processing_times = []\n        \n        # Process same request 100 times\n        for i in range(100):\n            try:\n                start_time = time.time()\n                response = self.agent.process_request(request)\n                processing_time = time.time() - start_time\n                \n                if 'recommendations' in response:\n                    success_count += 1\n                    processing_times.append(processing_time)\n                else:\n                    error_count += 1\n                    \n            except Exception as e:\n                error_count += 1\n        \n        # Calculate reliability metrics\n        success_rate = success_count / 100\n        avg_processing_time = np.mean(processing_times)\n        std_processing_time = np.std(processing_times)\n        \n        print(f\"Reliability test: {success_count}/100 successful ({success_rate*100:.1f}%)\")\n        print(f\"Average processing time: {avg_processing_time:.3f}s Â± {std_processing_time:.3f}s\")\n        \n        # Reliability requirements\n        self.assertGreaterEqual(success_rate, 0.95)  # 95% success rate\n        self.assertLess(std_processing_time, avg_processing_time * 0.5)  # Consistent timing\n    \n    def test_edge_case_handling(self):\n        \"\"\"Test handling of edge cases\"\"\"\n        edge_cases = [\n            {\n                'name': 'same_source_destination',\n                'request': {\n                    'source': 'Downtown',\n                    'destination': 'Downtown',\n                    'preferred_time': '08:00',\n                    'day_of_week': 1,\n                    'preferences': ['time_efficient']\n                }\n            },\n            {\n                'name': 'midnight_time',\n                'request': {\n                    'source': 'Downtown',\n                    'destination': 'Airport',\n                    'preferred_time': '00:00',\n                    'day_of_week': 1,\n                    'preferences': ['time_efficient']\n                }\n            },\n            {\n                'name': 'weekend_request',\n                'request': {\n                    'source': 'Downtown',\n                    'destination': 'Airport',\n                    'preferred_time': '08:00',\n                    'day_of_week': 6,  # Saturday\n                    'preferences': ['eco_friendly']\n                }\n            }\n        ]\n        \n        for case in edge_cases:\n            with self.subTest(case=case['name']):\n                try:\n                    response = self.agent.process_request(case['request'])\n                    \n                    # Should handle gracefully\n                    self.assertTrue(\n                        'recommendations' in response or 'error' in response,\n                        f\"Edge case {case['name']} not handled properly\"\n                    )\n                    \n                except Exception as e:\n                    self.fail(f\"Edge case {case['name']} caused exception: {str(e)}\")\n\nif __name__ == '__main__':\n    # Run tests with detailed output\n    unittest.main(verbosity=2, buffer=True)"